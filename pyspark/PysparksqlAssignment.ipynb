{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8c863b5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import findspark\n",
    "findspark.init()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0a01e8ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark\n",
    "from pyspark.sql import SparkSession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a8b0ca02",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark=SparkSession.builder.appName('ItemsApp').getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "02ff1c01",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=spark.read.csv('d:\\\\item_details.csv',header=True,inferSchema=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5e49ed97",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+---------+---------+--------+-----+---+\n",
      "|item id|item name|item cost|supplier|grade|qty|\n",
      "+-------+---------+---------+--------+-----+---+\n",
      "|      8|    chalk|    65.76|       X|    A|  2|\n",
      "|     12|   Pencil|     null|       Y|    B|  3|\n",
      "|     13|      Pen|     43.0|       X|    A|  5|\n",
      "|     15|   Duster|     54.0|       Y|    C|  1|\n",
      "|     23|    Scale|     10.0|    null|    A|  2|\n",
      "|      8|    chalk|    65.76|       X|    A|  2|\n",
      "+-------+---------+---------+--------+-----+---+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cb502650",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>item id</th>\n",
       "      <th>item name</th>\n",
       "      <th>item cost</th>\n",
       "      <th>supplier</th>\n",
       "      <th>grade</th>\n",
       "      <th>qty</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8</td>\n",
       "      <td>chalk</td>\n",
       "      <td>65.76</td>\n",
       "      <td>X</td>\n",
       "      <td>A</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>12</td>\n",
       "      <td>Pencil</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Y</td>\n",
       "      <td>B</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>13</td>\n",
       "      <td>Pen</td>\n",
       "      <td>43.00</td>\n",
       "      <td>X</td>\n",
       "      <td>A</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   item id item name  item cost supplier grade  qty\n",
       "0        8     chalk      65.76        X     A    2\n",
       "1       12    Pencil        NaN        Y     B    3\n",
       "2       13       Pen      43.00        X     A    5"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.limit(3).toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7485c13",
   "metadata": {},
   "outputs": [],
   "source": [
    "From two separate CSV files (items.csv,Supplier.csv) fetch data in two pyspark dataframes.  \n",
    "Please complete following tasks given with based on it....                                                                                             #1.show item details and Supplier details supplied by MR.X\n",
    "#2.show supplier details who has supplied items with cost>1000\n",
    "#3.show all item details whos supplier details are not available\n",
    "#4.show item details whose supplier details are available\n",
    "#5.show item details along with supplier details for such items ,for which supplier details are  available and item name starts with 'b'\n",
    "#6.Show supplier wise number of items supplied, sum ,min ,max total of itemcost .\n",
    "#all item cost supplied\n",
    "#7.join overall items available in 2 stores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "61027111",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=spark.read.csv('d:\\\\item.csv',header=True,inferSchema=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "88235e10",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1=spark.read.csv('d:\\\\supplier.csv',header=True,inferSchema=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "e715d44e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.createOrReplaceTempView('tempview1')\n",
    "df1.createOrReplaceTempView('tempview2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "1ddd3885",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+--------+--------+------+------+--------+\n",
      "|itemid|itemname|itemcost|sup_id|sup_id|Sup_name|\n",
      "+------+--------+--------+------+------+--------+\n",
      "|    15|   chalk|    1000|     1|     1|       X|\n",
      "|    11|  Pencil|     900|     1|     1|       X|\n",
      "+------+--------+--------+------+------+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#1.show item detailes supplied by mr x\n",
    "pd=spark.sql('select * from tempview1 as t join tempview2 as t1 on t.sup_id==t1.sup_id where sup_name==\"X\" ')\n",
    "pd.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "88c2c1b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+--------+------+--------+--------+------+\n",
      "|sup_id|Sup_name|itemid|itemname|itemcost|sup_id|\n",
      "+------+--------+------+--------+--------+------+\n",
      "|     2|    null|    13|     Pen|    1500|     2|\n",
      "|     3|       Z|    15|  Duster|    1600|     3|\n",
      "+------+--------+------+--------+--------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#2.show supplier details who has supplied items with cost>1000\n",
    "pd=spark.sql('select * from tempview2 as t join tempview1 as t1 on t.sup_id==t1.sup_id where itemcost>1000')\n",
    "pd.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "c2262fab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+--------+--------+------+------+--------+\n",
      "|itemid|itemname|itemcost|sup_id|sup_id|sup_name|\n",
      "+------+--------+--------+------+------+--------+\n",
      "|    13|     Pen|    1500|     2|     2|    null|\n",
      "|    78|   Scale|     100|     2|     2|    null|\n",
      "+------+--------+--------+------+------+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#3.show all item details whos supplier details are not available\n",
    "pd1=spark.sql('select * from tempview1 as t join tempview2 as t1 on t.sup_id==t1.sup_id where t1.sup_name is null')\n",
    "pd1.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "21a149e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+--------+--------+------+------+--------+\n",
      "|itemid|itemname|itemcost|sup_id|sup_id|sup_name|\n",
      "+------+--------+--------+------+------+--------+\n",
      "|    15|   chalk|    1000|     1|     1|       X|\n",
      "|    11|  Pencil|     900|     1|     1|       X|\n",
      "|    15|  Duster|    1600|     3|     3|       Z|\n",
      "|    89|   chalk|     600|     4|     4|       A|\n",
      "+------+--------+--------+------+------+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#4.show item details whose supplier details are available\n",
    "pd1=spark.sql('select * from tempview1 as t join tempview2 as t1 on t.sup_id==t1.sup_id where sup_name!=\" \"')\n",
    "pd1.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "147c7701",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+--------+--------+------+------+--------+\n",
      "|itemid|itemname|itemcost|sup_id|sup_id|sup_name|\n",
      "+------+--------+--------+------+------+--------+\n",
      "|    15|   chalk|    1000|     1|     1|       X|\n",
      "|    89|   chalk|     600|     4|     4|       A|\n",
      "+------+--------+--------+------+------+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#5.show item details along with supplier details for such items,for which supplier details are  available and item name starts with 'b'\n",
    "pd3=spark.sql('select * from tempview1 as t join tempview2 as t1 on t.sup_id==t1.sup_id where t.itemname like \"c%\"')\n",
    "pd3.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "2bf4db30",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-------------+-------------+-------------+\n",
      "|sup_id|max(itemcost)|min(itemcost)|sum(itemcost)|\n",
      "+------+-------------+-------------+-------------+\n",
      "|     1|         1000|          900|         1900|\n",
      "|     3|         1600|         1600|         1600|\n",
      "|     4|          600|          600|          600|\n",
      "|     2|         1500|          100|         1600|\n",
      "+------+-------------+-------------+-------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#6.Show supplier wise number of items supplied, sum ,min ,max total of itemcost .\n",
    "pd4=spark.sql('select t1.sup_id,max(t.itemcost),min(t.itemcost),sum(t.itemcost) from tempview1 as t join tempview2 as t1 on t.sup_id==t1.sup_id group by(t1.sup_id) ')\n",
    "pd4.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "023afbdc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+--------+--------+------+------+--------+\n",
      "|itemid|itemname|itemcost|sup_id|sup_id|sup_name|\n",
      "+------+--------+--------+------+------+--------+\n",
      "|    15|   chalk|    1000|     1|     1|       X|\n",
      "|    11|  Pencil|     900|     1|     1|       X|\n",
      "|    13|     Pen|    1500|     2|     2|    null|\n",
      "|    15|  Duster|    1600|     3|     3|       Z|\n",
      "|    78|   Scale|     100|     2|     2|    null|\n",
      "|    89|   chalk|     600|     4|     4|       A|\n",
      "+------+--------+--------+------+------+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#7.join overall items available in 2 stores\n",
    "pd6=df.join(df1,df.sup_id==df1.sup_id)\n",
    "pd6.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a9b9f8c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
